{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "#import memtorch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from memtorch.utils import LoadMNIST\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadMNIST(batch_size=32, validation=True, num_workers=1):\n",
    "    \"\"\"Method to load the MNIST dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_size : int\n",
    "        Batch size.\n",
    "    validation : bool\n",
    "        Load the validation set (True).\n",
    "    num_workers : int\n",
    "        Number of workers to use.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of torch.utils.data\n",
    "        The train, validiation, and test loaders.\n",
    "    \"\"\"\n",
    "    root = \"data\"\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    full_train_set = torchvision.datasets.MNIST(\n",
    "        root=root, train=True, transform=transform, download=True\n",
    "    )\n",
    "    test_set = torchvision.datasets.MNIST(\n",
    "        root=root, train=False, transform=transform, download=True\n",
    "    )\n",
    "    if validation:\n",
    "        train_size = int(0.8 * len(full_train_set))\n",
    "        validation_size = len(full_train_set) - train_size\n",
    "        train_set, validation_set = torch.utils.data.random_split(\n",
    "            full_train_set, [train_size, validation_size]\n",
    "        )\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    "        )\n",
    "        validation_loader = torch.utils.data.DataLoader(\n",
    "            validation_set, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    "        )\n",
    "    else:\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            full_train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    "        )\n",
    "        validation_loader = None\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_set, batch_size=int(batch_size / 2), shuffle=False, num_workers=num_workers\n",
    "    )\n",
    "    return train_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "def test(model, test_loader):\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):        \n",
    "        output = model(data.to(device))\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct += pred.eq(target.to(device).data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    return 100. * float(correct) / float(len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "epochs = 1\n",
    "learning_rate = 1e-1\n",
    "step_lr = 5\n",
    "batch_size = 256\n",
    "train_loader, validation_loader, test_loader = LoadMNIST(batch_size=batch_size, validation=False)\n",
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print('Epoch: [%d]\\t\\t' % (epoch + 1), end='')\n",
    "    if epoch % step_lr == 0:\n",
    "        learning_rate = learning_rate * 0.1\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.to(device))\n",
    "        loss = criterion(output, target.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    accuracy = test(model, test_loader)\n",
    "    print('%2.2f%%' % accuracy)\n",
    "    if accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'trained_model.pt')\n",
    "        best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_value(weights, stable_weights):\n",
    "    nearest_values = np.zeros_like(weights)\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            min_diff = np.inf\n",
    "            for k in range(stable_weights.shape[0]):\n",
    "                diff = abs(weights[i, j] - stable_weights[k])\n",
    "                if diff < min_diff:\n",
    "                    min_diff = diff\n",
    "                    nearest_val = stable_weights[k]\n",
    "            nearest_values[i, j] = nearest_val\n",
    "    return nearest_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Const- att + No_DRIFT\n",
    "mu_d1=[0.0408922482187778,0.0486397259465766,0.0659011822935616,0.0873910306988032,0.12031171987342,0.179347901868409,0.370734877791567,0.980002642655943]\n",
    "mu_d1 = np.array(mu_d1)\n",
    "fc1_weights = model.fc1.weight.data.cpu().numpy()\n",
    "\n",
    "w_min_fc1, w_max_fc1 = fc1_weights.min(), fc1_weights.max()\n",
    "\n",
    "stable_weights_d1=w_min_fc1+mu_d1*(w_max_fc1-w_min_fc1)\n",
    "\n",
    "n_states = np.arange(2, 18, 2)\n",
    "\n",
    "fc1_nearest_values = find_nearest_value(fc1_weights, stable_weights_d1)\n",
    "model.fc1.weight.data = torch.Tensor(fc1_nearest_values).to(device)\n",
    "\n",
    "accuracy = test(model, test_loader)\n",
    "print('Accuracy: %2.2f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu' \n",
    "epochs = 1\n",
    "learning_rate = 1e-1\n",
    "step_lr = 5\n",
    "batch_size = 256\n",
    "train_loader, validation_loader, test_loader = LoadMNIST(batch_size=batch_size, validation=False)\n",
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print('Epoch: [%d]\\t\\t' % (epoch + 1), end='')\n",
    "    if epoch % step_lr == 0:\n",
    "        learning_rate = learning_rate * 0.1\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.to(device))\n",
    "        loss = criterion(output, target.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    accuracy = test(model, test_loader)\n",
    "    print('%2.2f%%' % accuracy)\n",
    "    if accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'trained_model.pt')\n",
    "        best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Const- att + DRIFT\n",
    "mu_d2=[0.00290018894456321,0.00579987438695429,0.0124871185313898,0.0211661731196688,0.0351172867682934,0.0618268318738881,0.15689536442912,0.507524252429167]\n",
    "#stable_weights_sigma_d2=[0.00119773088256169,0.00146230640474838,0.00240189995120909,0.00295921207758356,0.00553294617161122,0.0180128583290658,0.0400563282515534,0.0280814267250356]\n",
    "mu_d2=np.array(mu_d2)\n",
    "\n",
    "\n",
    "\n",
    "fc1_weights = model.fc1.weight.data.cpu().numpy()\n",
    "\n",
    "w_min_fc1, w_max_fc1 = fc1_weights.min(), fc1_weights.max()\n",
    "\n",
    "stable_weights_d2=w_min_fc1+mu_d2*(w_max_fc1-w_min_fc1)\n",
    "\n",
    "n_states = np.arange(2, 18, 2)\n",
    "\n",
    "fc1_nearest_values = find_nearest_value(fc1_weights, stable_weights_d2)\n",
    "model.fc1.weight.data = torch.Tensor(fc1_nearest_values).to(device)\n",
    "\n",
    "accuracy = test(model, test_loader)\n",
    "print('Accuracy: %2.2f%%' % accuracy)\n",
    "w_min_fc1, w_max_fc1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
